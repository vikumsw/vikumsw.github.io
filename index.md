---
layout: page
title: Welcome
tags: [satwik, kottur, home, cmu, computer vision, machine learning, natural language processing, graduate]
modified: 2014-08-08T20:53:07.573882-04:00
comments: false
---

Hi!

I am a fifth year PhD student at [ECE](http://www.ece.cmu.edu/) department, [Carnegie Mellon University](http://www.cmu.edu/). I work with [Prof. Jos&eacute; Moura](http://users.ece.cmu.edu/~moura/), in the fields of computer vision, natural language and machine learning. 

My interests are in the intersection of natural language and computer vision, and 
broadly, to solve multimodal AI problems using deep learning techniques.
I closely collaborate with [Prof. Devi Parikh](https://www.cc.gatech.edu/~parikh/) and 
[Prof. Dhruv Batra](https://www.cc.gatech.edu/~dbatra/) from Georgia Tech on tasks that 
require multimodal reasoning (vision and language), for example, visual dialog 
([VisDial](visualdialog.org)).

I completed my undergraduate from Department of Electrical Engineering ([EE](http://www.ee.iitb.ac.in/)), [Indian Institute of Technology, Bombay](https://www.iitb.ac.in), in 2014 along with a minor in Computer Science and Engineering ([CSE](https://www.cse.iitb.ac.in/)). I worked under [Prof. Subhasis Chaudhuri](https://www.ee.iitb.ac.in/~sc/) on Human Activity Recognition for my undergraduate thesis. 

<button type="button" class="btn btn-danger" style="pointer-events:none;">NEW</button>
**I am currently on the job market for industry research positions in AI.**  
[[Google Scholar](https://scholar.google.com/citations?user=iQxXG8kAAAAJ&hl=en)]

----

<h3 align="center">News</h3>
<table class='news-table'>
    <col width="15%">
    <col width="85%">
    <tr>
        <td valign="top"><strong>[July 2018]</strong></td>
        <td>Our paper on <a>Visual Coreference Resolution in Visual Dialog</a> 
        has been accepted at <a href="https://eccv2018.org/">ECCV, 2018</a>
        </td>
    </tr>
    <tr>
        <td valign="top"><strong>[Jan 2018]</strong></td>
        <td>Interning at <a href="https://ai.google/research/teams/brain">Google Brain</a> this summer, with <a href="https://ai.stanford.edu/~gal/">Gal Chechik</a> and <a href="http://bengio.abracadoudou.com/">Samy Bengio</a></td>
    </tr>
    <tr>
        <td valign="top"><strong>[Dec 2017]</strong></td>
        <td>I was awarded the inaugural <a href='https://snapresearchfellowship.splashthat.com/'>Snap Inc. Research Fellowship</a>, 2017</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Dec 2017]</strong></td>
        <td>I received a <a href='https://nips.cc/Conferences/2017/Awards'>Best Reviewer Award</a> at NIPS 2017</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Sept 2017]</strong></td>
        <td>Our paper on <a>Deepsets</a> has been accepted as an <b> oral</b> at NIPS, 2017</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Aug 2017]</strong></td>
        <td>Our paper on <a>Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog</a> won the <b>best short paper</b> award at EMNLP 2017</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Aug 2017]</strong></td>
        <td>Our paper on <a>Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning</a> has been accepted as an <b> oral</b> at ICCV, 2017</td>
    </tr>
    <tr>
        <td valign="top"><strong>[July 2017]</strong></td>
        <td>Our paper on <a>Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog</a> has been accepted as an <b> oral</b> at EMNLP, 2017</td>
    </tr>
    <tr>
        <td valign="top"><strong>[June 2017]</strong></td>
        <td>Checkout our latest paper, <a href="https://arxiv.org/abs/1706.08502">Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog</a>, on Arxiv.
        Github code available <a href="https://github.com/batra-mlp-lab/lang-emerge">here</a></td>
    </tr>
    <tr>
        <td valign="top"><strong>[May 2017]</strong></td>
        <td>Our paper on <a>Canopy</a> got accepted at ICML, 2017</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Apr 2017]</strong></td>
        <td>Our paper on <a>Exploring Personalized Neural Conversational Models</a> got accepted at IJCAI, 2017</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Apr 2017]</strong></td>
        <td>Find our Github code for Visual Dialog <a href="https://github.com/batra-mlp-lab/visdial">here</a></td>
    </tr>
    <tr>
        <td valign="top"><strong>[Mar 2017]</strong></td>
        <td>Checkout our latest paper, <a href="https://arxiv.org/abs/1703.06585">Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning</a>, on arXiv</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Mar 2017]</strong></td>
        <td>Checkout our latest paper, <a href="https://arxiv.org/abs/1703.06114">Deepsets</a>, on arXiv</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Mar 2017]</strong></td>
        <td>Our paper on <a href="https://visualdialog.org/">Visual Dialog</a> got accepted at CVPR, 2017 as a <b>Spotlight</b></td>
    </tr>
    <tr>
        <td valign="top"><strong>[Mar 2017]</strong></td>
        <td>Interning at <a href="https://research.fb.com/category/facebook-ai-research-fair/">Facebook AI Research (FAIR)</a> this summer, with <a href="http://rohrbach.vision/">Marcus Rohrbach</a></td>
    </tr>
    <tr>
        <td valign="top"><strong>[Nov 2016]</strong></td>
        <td>Checkout our latest paper, <a href="http://arxiv.org/abs/1611.08669">Visual Dialog</a>, on arXiv</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Aug 2016]</strong></td>
        <td>Serving as Vice-President of <a href="https://www.ece.cmu.edu/~ego/"> ECE Graduate Organization</a>, CMU</td>
    </tr>
    <tr>
        <td valign="top"><strong>[May 2016]</strong></td>
        <td>Serving as a reviewer for <a href="https://nips.cc/"> NIPS 2016</a></td>
    </tr>
    <tr>
        <td valign="top"><strong>[Mar 2016]</strong></td>
        <td>Our paper on <a href="http://arxiv.org/abs/1511.07067">Visual Word2Vec</a> got accepted to CVPR, 2016</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Dec 2015]</strong></td>
        <td>I would be interning at <a href="https://www.snapchat.com/">Snapchat</a> this summer</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Nov 2015]</strong></td>
        <td>Checkout our latest paper, <a href="http://arxiv.org/abs/1511.07067">Visual Word2Vec</a>, on arXiv</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Oct 2015]</strong></td>
        <td>Checkout our paper, <a href="http://opt-ml.org/papers/OPT2015_paper_52.pdf">Comparing Gibbs, EM and SEM for MAP Inference in Mixture Models</a>, which got accepted in NIPS: <a href="http://opt-ml.org/papers.html">OPT</a> workshop, 2015</td>
    </tr>
</table>

----

<h3 align="center">Affiliations</h3>
<table align="center" class='affl-pic'>
    <tr>
        <td>
            <a href="http://www.cmu.edu/">
            <img src="/images/cmu-logo.png"></a>
        </td>
        <td>
            <a href="http://www.iitb.ac.in/">
            <img src="/images/iitb-logo.jpeg"></a>
        </td>
        <td>
            <a href="http://viterbi.usc.edu/">
            <img src="/images/viterbi-logo.jpg"></a>
        </td>
    <tr>
    <tr>
        <td>Carnegie Mellon University<br>2014-present</td>
        <td>IIT Bombay<br>2010-2014</td>
        <td>Viterbi School, USC<br>Summer 2013</td>
    </tr>
    </tr>
        <td>
            <a href="https://www.snapchat.com/">
            <img src="/images/snapchat-logo.png"></a>
        </td>
        <td>
            <a href="https://research.fb.com/category/facebook-ai-research-fair/">
            <img src="/images/fair-logo.png"></a>
        </td>
        <td>
            <a href="https://ai.google/research/teams/brain">
            <img src="/images/google-logo.png"></a>
        </td>
    </tr>
    <tr>
        <td>Snapchat Research<br>Summer 2016</td>
        <td>Facebook AI Research<br>Summer 2017</td>
        <td>Google Brain<br>Summer 2018</td>
    </tr>
</table>
